{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "additionalProperties": false,
    "definitions": {
        "AbortSignal": {
            "additionalProperties": false,
            "description": "A signal object that allows you to communicate with a DOM request (such as a Fetch) and abort it if required via an AbortController object.",
            "properties": {
                "aborted": {
                    "description": "Returns true if this AbortSignal's AbortController has signaled to abort, and false otherwise.",
                    "type": "boolean"
                }
            },
            "required": [
                "aborted"
            ],
            "type": "object"
        },
        "Duplex": {
            "additionalProperties": false,
            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`",
            "properties": {
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "allowHalfOpen",
                "closed",
                "destroyed",
                "errored",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "Error": {
            "additionalProperties": false,
            "properties": {
                "cause": {},
                "message": {
                    "type": "string"
                },
                "name": {
                    "type": "string"
                },
                "stack": {
                    "type": "string"
                }
            },
            "required": [
                "message",
                "name"
            ],
            "type": "object"
        },
        "Http2ServerRequest": {
            "additionalProperties": false,
            "description": "A `Http2ServerRequest` object is created by {@link Server} or {@link SecureServer} and passed as the first argument to the `'request'` event. It may be used to access a request status,\nheaders, and\ndata.",
            "properties": {
                "aborted": {
                    "description": "The `request.aborted` property will be `true` if the request has\nbeen aborted.",
                    "type": "boolean"
                },
                "authority": {
                    "description": "The request authority pseudo header field. Because HTTP/2 allows requests\nto set either `:authority` or `host`, this value is derived from`req.headers[':authority']` if present. Otherwise, it is derived from`req.headers['host']`.",
                    "type": "string"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "complete": {
                    "description": "The `request.complete` property will be `true` if the request has\nbeen completed, aborted, or destroyed.",
                    "type": "boolean"
                },
                "connection": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "$ref": "#/definitions/TLSSocket"
                        }
                    ],
                    "description": "See `request.socket`."
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "headers": {
                    "$ref": "#/definitions/IncomingHttpHeaders_1",
                    "description": "The request/response headers object.\n\nKey-value pairs of header names and values. Header names are lower-cased.\n\n```js\n// Prints something like:\n//\n// { 'user-agent': 'curl/7.22.0',\n//   host: '127.0.0.1:8000',\n//   accept: '*' }\nconsole.log(request.headers);\n```\n\nSee `HTTP/2 Headers Object`.\n\nIn HTTP/2, the request path, host name, protocol, and method are represented as\nspecial headers prefixed with the `:` character (e.g. `':path'`). These special\nheaders will be included in the `request.headers` object. Care must be taken not\nto inadvertently modify these special headers or errors may occur. For instance,\nremoving all headers from the request will cause errors to occur:\n\n```js\nremoveAllHeaders(request.headers);\nassert(request.url);   // Fails because the :path header has been removed\n```"
                },
                "httpVersion": {
                    "description": "In case of server request, the HTTP version sent by the client. In the case of\nclient response, the HTTP version of the connected-to server. Returns`'2.0'`.\n\nAlso `message.httpVersionMajor` is the first integer and`message.httpVersionMinor` is the second.",
                    "type": "string"
                },
                "httpVersionMajor": {
                    "type": "number"
                },
                "httpVersionMinor": {
                    "type": "number"
                },
                "method": {
                    "description": "The request method as a string. Read-only. Examples: `'GET'`, `'DELETE'`.",
                    "type": "string"
                },
                "rawHeaders": {
                    "description": "The raw request/response headers list exactly as they were received.\n\nThe keys and values are in the same list. It is _not_ a\nlist of tuples. So, the even-numbered offsets are key values, and the\nodd-numbered offsets are the associated values.\n\nHeader names are not lowercased, and duplicates are not merged.\n\n```js\n// Prints something like:\n//\n// [ 'user-agent',\n//   'this is invalid because there can be only one',\n//   'User-Agent',\n//   'curl/7.22.0',\n//   'Host',\n//   '127.0.0.1:8000',\n//   'ACCEPT',\n//   '*' ]\nconsole.log(request.rawHeaders);\n```",
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "rawTrailers": {
                    "description": "The raw request/response trailer keys and values exactly as they were\nreceived. Only populated at the `'end'` event.",
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "scheme": {
                    "description": "The request scheme pseudo header field indicating the scheme\nportion of the target URL.",
                    "type": "string"
                },
                "socket": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "$ref": "#/definitions/TLSSocket"
                        }
                    ],
                    "description": "Returns a `Proxy` object that acts as a `net.Socket` (or `tls.TLSSocket`) but\napplies getters, setters, and methods based on HTTP/2 logic.\n\n`destroyed`, `readable`, and `writable` properties will be retrieved from and\nset on `request.stream`.\n\n`destroy`, `emit`, `end`, `on` and `once` methods will be called on`request.stream`.\n\n`setTimeout` method will be called on `request.stream.session`.\n\n`pause`, `read`, `resume`, and `write` will throw an error with code`ERR_HTTP2_NO_SOCKET_MANIPULATION`. See `Http2Session and Sockets` for\nmore information.\n\nAll other interactions will be routed directly to the socket. With TLS support,\nuse `request.socket.getPeerCertificate()` to obtain the client's\nauthentication details."
                },
                "stream": {
                    "$ref": "#/definitions/ServerHttp2Stream",
                    "description": "The `Http2Stream` object backing the request."
                },
                "trailers": {
                    "$ref": "#/definitions/IncomingHttpHeaders_1",
                    "description": "The request/response trailers object. Only populated at the `'end'` event."
                },
                "url": {
                    "description": "Request URL string. This contains only the URL that is present in the actual\nHTTP request. If the request is:\n\n```http\nGET /status?name=ryan HTTP/1.1\nAccept: text/plain\n```\n\nThen `request.url` will be:\n\n```js\n'/status?name=ryan'\n```\n\nTo parse the url into its parts, `new URL()` can be used:\n\n```console\n$ node\n> new URL('/status?name=ryan', 'http://example.com')\nURL {\n  href: 'http://example.com/status?name=ryan',\n  origin: 'http://example.com',\n  protocol: 'http:',\n  username: '',\n  password: '',\n  host: 'example.com',\n  hostname: 'example.com',\n  port: '',\n  pathname: '/status',\n  search: '?name=ryan',\n  searchParams: URLSearchParams { 'name' => 'ryan' },\n  hash: ''\n}\n```",
                    "type": "string"
                }
            },
            "required": [
                "aborted",
                "authority",
                "closed",
                "complete",
                "connection",
                "destroyed",
                "errored",
                "headers",
                "httpVersion",
                "httpVersionMajor",
                "httpVersionMinor",
                "method",
                "rawHeaders",
                "rawTrailers",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "scheme",
                "socket",
                "stream",
                "trailers",
                "url"
            ],
            "type": "object"
        },
        "Http2ServerResponse": {
            "additionalProperties": false,
            "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
            "properties": {
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "connection": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "$ref": "#/definitions/TLSSocket"
                        }
                    ],
                    "description": "See `response.socket`."
                },
                "destroyed": {
                    "description": "Is `true` after `writable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "finished": {
                    "description": "Boolean value that indicates whether the response has completed. Starts\nas `false`. After `response.end()` executes, the value will be `true`.",
                    "type": "boolean"
                },
                "headersSent": {
                    "description": "True if headers were sent, false otherwise (read-only).",
                    "type": "boolean"
                },
                "req": {
                    "$ref": "#/definitions/Http2ServerRequest",
                    "description": "A reference to the original HTTP2 request object."
                },
                "sendDate": {
                    "description": "When true, the Date header will be automatically generated and sent in\nthe response if it is not already present in the headers. Defaults to true.\n\nThis should only be disabled for testing; HTTP requires the Date header\nin responses.",
                    "type": "boolean"
                },
                "socket": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "$ref": "#/definitions/TLSSocket"
                        }
                    ],
                    "description": "Returns a `Proxy` object that acts as a `net.Socket` (or `tls.TLSSocket`) but\napplies getters, setters, and methods based on HTTP/2 logic.\n\n`destroyed`, `readable`, and `writable` properties will be retrieved from and\nset on `response.stream`.\n\n`destroy`, `emit`, `end`, `on` and `once` methods will be called on`response.stream`.\n\n`setTimeout` method will be called on `response.stream.session`.\n\n`pause`, `read`, `resume`, and `write` will throw an error with code`ERR_HTTP2_NO_SOCKET_MANIPULATION`. See `Http2Session and Sockets` for\nmore information.\n\nAll other interactions will be routed directly to the socket.\n\n```js\nconst http2 = require('http2');\nconst server = http2.createServer((req, res) => {\n  const ip = req.socket.remoteAddress;\n  const port = req.socket.remotePort;\n  res.end(`Your IP address is ${ip} and your source port is ${port}.`);\n}).listen(3000);\n```"
                },
                "statusCode": {
                    "description": "When using implicit headers (not calling `response.writeHead()` explicitly),\nthis property controls the status code that will be sent to the client when\nthe headers get flushed.\n\n```js\nresponse.statusCode = 404;\n```\n\nAfter response header was sent to the client, this property indicates the\nstatus code which was sent out.",
                    "type": "number"
                },
                "statusMessage": {
                    "description": "Status message is not supported by HTTP/2 (RFC 7540 8.1.2.4). It returns\nan empty string.",
                    "enum": [
                        ""
                    ],
                    "type": "string"
                },
                "stream": {
                    "$ref": "#/definitions/ServerHttp2Stream",
                    "description": "The `Http2Stream` object backing the response."
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "closed",
                "connection",
                "destroyed",
                "errored",
                "finished",
                "headersSent",
                "req",
                "sendDate",
                "socket",
                "statusCode",
                "statusMessage",
                "stream",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "Http2Session": {
            "additionalProperties": false,
            "properties": {
                "alpnProtocol": {
                    "description": "Value will be `undefined` if the `Http2Session` is not yet connected to a\nsocket, `h2c` if the `Http2Session` is not connected to a `TLSSocket`, or\nwill return the value of the connected `TLSSocket`'s own `alpnProtocol`property.",
                    "type": "string"
                },
                "closed": {
                    "description": "Will be `true` if this `Http2Session` instance has been closed, otherwise`false`.",
                    "type": "boolean"
                },
                "connecting": {
                    "description": "Will be `true` if this `Http2Session` instance is still connecting, will be set\nto `false` before emitting `connect` event and/or calling the `http2.connect`callback.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Will be `true` if this `Http2Session` instance has been destroyed and must no\nlonger be used, otherwise `false`.",
                    "type": "boolean"
                },
                "encrypted": {
                    "description": "Value is `undefined` if the `Http2Session` session socket has not yet been\nconnected, `true` if the `Http2Session` is connected with a `TLSSocket`,\nand `false` if the `Http2Session` is connected to any other kind of socket\nor stream.",
                    "type": "boolean"
                },
                "localSettings": {
                    "$ref": "#/definitions/Settings",
                    "description": "A prototype-less object describing the current local settings of this`Http2Session`. The local settings are local to _this_`Http2Session` instance."
                },
                "originSet": {
                    "description": "If the `Http2Session` is connected to a `TLSSocket`, the `originSet` property\nwill return an `Array` of origins for which the `Http2Session` may be\nconsidered authoritative.\n\nThe `originSet` property is only available when using a secure TLS connection.",
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "pendingSettingsAck": {
                    "description": "Indicates whether the `Http2Session` is currently waiting for acknowledgment of\na sent `SETTINGS` frame. Will be `true` after calling the`http2session.settings()` method. Will be `false` once all sent `SETTINGS`frames have been acknowledged.",
                    "type": "boolean"
                },
                "remoteSettings": {
                    "$ref": "#/definitions/Settings",
                    "description": "A prototype-less object describing the current remote settings of this`Http2Session`. The remote settings are set by the _connected_ HTTP/2 peer."
                },
                "socket": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "$ref": "#/definitions/TLSSocket"
                        }
                    ],
                    "description": "Returns a `Proxy` object that acts as a `net.Socket` (or `tls.TLSSocket`) but\nlimits available methods to ones safe to use with HTTP/2.\n\n`destroy`, `emit`, `end`, `pause`, `read`, `resume`, and `write` will throw\nan error with code `ERR_HTTP2_NO_SOCKET_MANIPULATION`. See `Http2Session and Sockets` for more information.\n\n`setTimeout` method will be called on this `Http2Session`.\n\nAll other interactions will be routed directly to the socket."
                },
                "state": {
                    "$ref": "#/definitions/SessionState",
                    "description": "Provides miscellaneous information about the current state of the`Http2Session`.\n\nAn object describing the current status of this `Http2Session`."
                },
                "type": {
                    "description": "The `http2session.type` will be equal to`http2.constants.NGHTTP2_SESSION_SERVER` if this `Http2Session` instance is a\nserver, and `http2.constants.NGHTTP2_SESSION_CLIENT` if the instance is a\nclient.",
                    "type": "number"
                }
            },
            "required": [
                "closed",
                "connecting",
                "destroyed",
                "localSettings",
                "pendingSettingsAck",
                "remoteSettings",
                "socket",
                "state",
                "type"
            ],
            "type": "object"
        },
        "IncomingHttpHeaders": {
            "additionalProperties": false,
            "properties": {
                "accept": {
                    "type": "string"
                },
                "accept-language": {
                    "type": "string"
                },
                "accept-patch": {
                    "type": "string"
                },
                "accept-ranges": {
                    "type": "string"
                },
                "access-control-allow-credentials": {
                    "type": "string"
                },
                "access-control-allow-headers": {
                    "type": "string"
                },
                "access-control-allow-methods": {
                    "type": "string"
                },
                "access-control-allow-origin": {
                    "type": "string"
                },
                "access-control-expose-headers": {
                    "type": "string"
                },
                "access-control-max-age": {
                    "type": "string"
                },
                "access-control-request-headers": {
                    "type": "string"
                },
                "access-control-request-method": {
                    "type": "string"
                },
                "age": {
                    "type": "string"
                },
                "allow": {
                    "type": "string"
                },
                "alt-svc": {
                    "type": "string"
                },
                "authorization": {
                    "type": "string"
                },
                "cache-control": {
                    "type": "string"
                },
                "connection": {
                    "type": "string"
                },
                "content-disposition": {
                    "type": "string"
                },
                "content-encoding": {
                    "type": "string"
                },
                "content-language": {
                    "type": "string"
                },
                "content-length": {
                    "type": "string"
                },
                "content-location": {
                    "type": "string"
                },
                "content-range": {
                    "type": "string"
                },
                "content-type": {
                    "type": "string"
                },
                "cookie": {
                    "type": "string"
                },
                "date": {
                    "type": "string"
                },
                "etag": {
                    "type": "string"
                },
                "expect": {
                    "type": "string"
                },
                "expires": {
                    "type": "string"
                },
                "forwarded": {
                    "type": "string"
                },
                "from": {
                    "type": "string"
                },
                "host": {
                    "type": "string"
                },
                "if-match": {
                    "type": "string"
                },
                "if-modified-since": {
                    "type": "string"
                },
                "if-none-match": {
                    "type": "string"
                },
                "if-unmodified-since": {
                    "type": "string"
                },
                "last-modified": {
                    "type": "string"
                },
                "location": {
                    "type": "string"
                },
                "origin": {
                    "type": "string"
                },
                "pragma": {
                    "type": "string"
                },
                "proxy-authenticate": {
                    "type": "string"
                },
                "proxy-authorization": {
                    "type": "string"
                },
                "public-key-pins": {
                    "type": "string"
                },
                "range": {
                    "type": "string"
                },
                "referer": {
                    "type": "string"
                },
                "retry-after": {
                    "type": "string"
                },
                "sec-websocket-accept": {
                    "type": "string"
                },
                "sec-websocket-extensions": {
                    "type": "string"
                },
                "sec-websocket-key": {
                    "type": "string"
                },
                "sec-websocket-protocol": {
                    "type": "string"
                },
                "sec-websocket-version": {
                    "type": "string"
                },
                "set-cookie": {
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "strict-transport-security": {
                    "type": "string"
                },
                "tk": {
                    "type": "string"
                },
                "trailer": {
                    "type": "string"
                },
                "transfer-encoding": {
                    "type": "string"
                },
                "upgrade": {
                    "type": "string"
                },
                "user-agent": {
                    "type": "string"
                },
                "vary": {
                    "type": "string"
                },
                "via": {
                    "type": "string"
                },
                "warning": {
                    "type": "string"
                },
                "www-authenticate": {
                    "type": "string"
                }
            },
            "type": "object"
        },
        "IncomingHttpHeaders_1": {
            "additionalProperties": false,
            "properties": {
                ":authority": {
                    "type": "string"
                },
                ":method": {
                    "type": "string"
                },
                ":path": {
                    "type": "string"
                },
                ":scheme": {
                    "type": "string"
                },
                "accept": {
                    "type": "string"
                },
                "accept-language": {
                    "type": "string"
                },
                "accept-patch": {
                    "type": "string"
                },
                "accept-ranges": {
                    "type": "string"
                },
                "access-control-allow-credentials": {
                    "type": "string"
                },
                "access-control-allow-headers": {
                    "type": "string"
                },
                "access-control-allow-methods": {
                    "type": "string"
                },
                "access-control-allow-origin": {
                    "type": "string"
                },
                "access-control-expose-headers": {
                    "type": "string"
                },
                "access-control-max-age": {
                    "type": "string"
                },
                "access-control-request-headers": {
                    "type": "string"
                },
                "access-control-request-method": {
                    "type": "string"
                },
                "age": {
                    "type": "string"
                },
                "allow": {
                    "type": "string"
                },
                "alt-svc": {
                    "type": "string"
                },
                "authorization": {
                    "type": "string"
                },
                "cache-control": {
                    "type": "string"
                },
                "connection": {
                    "type": "string"
                },
                "content-disposition": {
                    "type": "string"
                },
                "content-encoding": {
                    "type": "string"
                },
                "content-language": {
                    "type": "string"
                },
                "content-length": {
                    "type": "string"
                },
                "content-location": {
                    "type": "string"
                },
                "content-range": {
                    "type": "string"
                },
                "content-type": {
                    "type": "string"
                },
                "cookie": {
                    "type": "string"
                },
                "date": {
                    "type": "string"
                },
                "etag": {
                    "type": "string"
                },
                "expect": {
                    "type": "string"
                },
                "expires": {
                    "type": "string"
                },
                "forwarded": {
                    "type": "string"
                },
                "from": {
                    "type": "string"
                },
                "host": {
                    "type": "string"
                },
                "if-match": {
                    "type": "string"
                },
                "if-modified-since": {
                    "type": "string"
                },
                "if-none-match": {
                    "type": "string"
                },
                "if-unmodified-since": {
                    "type": "string"
                },
                "last-modified": {
                    "type": "string"
                },
                "location": {
                    "type": "string"
                },
                "origin": {
                    "type": "string"
                },
                "pragma": {
                    "type": "string"
                },
                "proxy-authenticate": {
                    "type": "string"
                },
                "proxy-authorization": {
                    "type": "string"
                },
                "public-key-pins": {
                    "type": "string"
                },
                "range": {
                    "type": "string"
                },
                "referer": {
                    "type": "string"
                },
                "retry-after": {
                    "type": "string"
                },
                "sec-websocket-accept": {
                    "type": "string"
                },
                "sec-websocket-extensions": {
                    "type": "string"
                },
                "sec-websocket-key": {
                    "type": "string"
                },
                "sec-websocket-protocol": {
                    "type": "string"
                },
                "sec-websocket-version": {
                    "type": "string"
                },
                "set-cookie": {
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "strict-transport-security": {
                    "type": "string"
                },
                "tk": {
                    "type": "string"
                },
                "trailer": {
                    "type": "string"
                },
                "transfer-encoding": {
                    "type": "string"
                },
                "upgrade": {
                    "type": "string"
                },
                "user-agent": {
                    "type": "string"
                },
                "vary": {
                    "type": "string"
                },
                "via": {
                    "type": "string"
                },
                "warning": {
                    "type": "string"
                },
                "www-authenticate": {
                    "type": "string"
                }
            },
            "type": "object"
        },
        "IncomingMessage": {
            "additionalProperties": false,
            "description": "An `IncomingMessage` object is created by {@link Server} or {@link ClientRequest} and passed as the first argument to the `'request'` and `'response'` event respectively. It may be used to\naccess response\nstatus, headers and data.\n\nDifferent from its `socket` value which is a subclass of `stream.Duplex`, the`IncomingMessage` itself extends `stream.Readable` and is created separately to\nparse and emit the incoming HTTP headers and payload, as the underlying socket\nmay be reused multiple times in case of keep-alive.",
            "properties": {
                "aborted": {
                    "description": "The `message.aborted` property will be `true` if the request has\nbeen aborted.",
                    "type": "boolean"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "complete": {
                    "description": "The `message.complete` property will be `true` if a complete HTTP message has\nbeen received and successfully parsed.\n\nThis property is particularly useful as a means of determining if a client or\nserver fully transmitted a message before a connection was terminated:\n\n```js\nconst req = http.request({\n  host: '127.0.0.1',\n  port: 8080,\n  method: 'POST'\n}, (res) => {\n  res.resume();\n  res.on('end', () => {\n    if (!res.complete)\n      console.error(\n        'The connection was terminated while the message was still being sent');\n  });\n});\n```",
                    "type": "boolean"
                },
                "connection": {
                    "$ref": "#/definitions/Socket",
                    "description": "Alias for `message.socket`."
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "headers": {
                    "$ref": "#/definitions/IncomingHttpHeaders",
                    "description": "The request/response headers object.\n\nKey-value pairs of header names and values. Header names are lower-cased.\n\n```js\n// Prints something like:\n//\n// { 'user-agent': 'curl/7.22.0',\n//   host: '127.0.0.1:8000',\n//   accept: '*' }\nconsole.log(request.getHeaders());\n```\n\nDuplicates in raw headers are handled in the following ways, depending on the\nheader name:\n\n* Duplicates of `age`, `authorization`, `content-length`, `content-type`,`etag`, `expires`, `from`, `host`, `if-modified-since`, `if-unmodified-since`,`last-modified`, `location`,\n`max-forwards`, `proxy-authorization`, `referer`,`retry-after`, `server`, or `user-agent` are discarded.\n* `set-cookie` is always an array. Duplicates are added to the array.\n* For duplicate `cookie` headers, the values are joined together with '; '.\n* For all other headers, the values are joined together with ', '."
                },
                "httpVersion": {
                    "description": "In case of server request, the HTTP version sent by the client. In the case of\nclient response, the HTTP version of the connected-to server.\nProbably either `'1.1'` or `'1.0'`.\n\nAlso `message.httpVersionMajor` is the first integer and`message.httpVersionMinor` is the second.",
                    "type": "string"
                },
                "httpVersionMajor": {
                    "type": "number"
                },
                "httpVersionMinor": {
                    "type": "number"
                },
                "method": {
                    "description": "**Only valid for request obtained from {@link Server}.**\n\nThe request method as a string. Read only. Examples: `'GET'`, `'DELETE'`.",
                    "type": "string"
                },
                "rawHeaders": {
                    "description": "The raw request/response headers list exactly as they were received.\n\nThe keys and values are in the same list. It is _not_ a\nlist of tuples. So, the even-numbered offsets are key values, and the\nodd-numbered offsets are the associated values.\n\nHeader names are not lowercased, and duplicates are not merged.\n\n```js\n// Prints something like:\n//\n// [ 'user-agent',\n//   'this is invalid because there can be only one',\n//   'User-Agent',\n//   'curl/7.22.0',\n//   'Host',\n//   '127.0.0.1:8000',\n//   'ACCEPT',\n//   '*' ]\nconsole.log(request.rawHeaders);\n```",
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "rawTrailers": {
                    "description": "The raw request/response trailer keys and values exactly as they were\nreceived. Only populated at the `'end'` event.",
                    "items": {
                        "type": "string"
                    },
                    "type": "array"
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "socket": {
                    "$ref": "#/definitions/Socket",
                    "description": "The `net.Socket` object associated with the connection.\n\nWith HTTPS support, use `request.socket.getPeerCertificate()` to obtain the\nclient's authentication details.\n\nThis property is guaranteed to be an instance of the `net.Socket` class,\na subclass of `stream.Duplex`, unless the user specified a socket\ntype other than `net.Socket` or internally nulled."
                },
                "statusCode": {
                    "description": "**Only valid for response obtained from {@link ClientRequest}.**\n\nThe 3-digit HTTP response status code. E.G. `404`.",
                    "type": "number"
                },
                "statusMessage": {
                    "description": "**Only valid for response obtained from {@link ClientRequest}.**\n\nThe HTTP response status message (reason phrase). E.G. `OK` or `Internal Server Error`.",
                    "type": "string"
                },
                "trailers": {
                    "$ref": "#/definitions/NodeJS.Dict<string>",
                    "description": "The request/response trailers object. Only populated at the `'end'` event."
                },
                "url": {
                    "description": "**Only valid for request obtained from {@link Server}.**\n\nRequest URL string. This contains only the URL that is present in the actual\nHTTP request. Take the following request:\n\n```http\nGET /status?name=ryan HTTP/1.1\nAccept: text/plain\n```\n\nTo parse the URL into its parts:\n\n```js\nnew URL(request.url, `http://${request.getHeaders().host}`);\n```\n\nWhen `request.url` is `'/status?name=ryan'` and`request.getHeaders().host` is `'localhost:3000'`:\n\n```console\n$ node\n> new URL(request.url, `http://${request.getHeaders().host}`)\nURL {\n  href: 'http://localhost:3000/status?name=ryan',\n  origin: 'http://localhost:3000',\n  protocol: 'http:',\n  username: '',\n  password: '',\n  host: 'localhost:3000',\n  hostname: 'localhost',\n  port: '3000',\n  pathname: '/status',\n  search: '?name=ryan',\n  searchParams: URLSearchParams { 'name' => 'ryan' },\n  hash: ''\n}\n```",
                    "type": "string"
                }
            },
            "required": [
                "aborted",
                "closed",
                "complete",
                "connection",
                "destroyed",
                "errored",
                "headers",
                "httpVersion",
                "httpVersionMajor",
                "httpVersionMinor",
                "rawHeaders",
                "rawTrailers",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "socket",
                "trailers"
            ],
            "type": "object"
        },
        "KeyObject": {
            "additionalProperties": false,
            "properties": {
                "passphrase": {
                    "description": "Optional passphrase.",
                    "type": "string"
                },
                "pem": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "Private keys in PEM format."
                }
            },
            "required": [
                "pem"
            ],
            "type": "object"
        },
        "ListenOptions": {
            "additionalProperties": false,
            "properties": {
                "backlog": {
                    "type": "number"
                },
                "exclusive": {
                    "type": "boolean"
                },
                "host": {
                    "type": "string"
                },
                "ipv6Only": {
                    "default": false,
                    "type": "boolean"
                },
                "path": {
                    "type": "string"
                },
                "port": {
                    "type": "number"
                },
                "readableAll": {
                    "type": "boolean"
                },
                "signal": {
                    "$ref": "#/definitions/AbortSignal",
                    "description": "When provided the corresponding `AbortController` can be used to cancel an asynchronous action."
                },
                "writableAll": {
                    "type": "boolean"
                }
            },
            "type": "object"
        },
        "NodeJS.Dict<string>": {
            "additionalProperties": {
                "$ref": "#/definitions/T"
            },
            "type": "object"
        },
        "OutgoingHttpHeaders": {
            "additionalProperties": false,
            "type": "object"
        },
        "PassThrough": {
            "additionalProperties": false,
            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams.",
            "properties": {
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "allowHalfOpen",
                "closed",
                "destroyed",
                "errored",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "PxfObject": {
            "additionalProperties": false,
            "properties": {
                "buf": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "PFX or PKCS12 encoded private key and certificate chain."
                },
                "passphrase": {
                    "description": "Optional passphrase.",
                    "type": "string"
                }
            },
            "required": [
                "buf"
            ],
            "type": "object"
        },
        "Readable": {
            "additionalProperties": false,
            "properties": {
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "closed",
                "destroyed",
                "errored",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode"
            ],
            "type": "object"
        },
        "SecureContext": {
            "additionalProperties": false,
            "properties": {
                "context": {}
            },
            "required": [
                "context"
            ],
            "type": "object"
        },
        "ServerHttp2Stream": {
            "additionalProperties": false,
            "properties": {
                "aborted": {
                    "description": "Set to `true` if the `Http2Stream` instance was aborted abnormally. When set,\nthe `'aborted'` event will have been emitted.",
                    "type": "boolean"
                },
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "bufferSize": {
                    "description": "This property shows the number of characters currently buffered to be written.\nSee `net.Socket.bufferSize` for details.",
                    "type": "number"
                },
                "closed": {
                    "description": "Set to `true` if the `Http2Stream` instance has been closed.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Set to `true` if the `Http2Stream` instance has been destroyed and is no longer\nusable.",
                    "type": "boolean"
                },
                "endAfterHeaders": {
                    "description": "Set to `true` if the `END_STREAM` flag was set in the request or response\nHEADERS frame received, indicating that no additional data should be received\nand the readable side of the `Http2Stream` will be closed.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "headersSent": {
                    "description": "True if headers were sent, false otherwise (read-only).",
                    "type": "boolean"
                },
                "id": {
                    "description": "The numeric stream identifier of this `Http2Stream` instance. Set to `undefined`if the stream identifier has not yet been assigned.",
                    "type": "number"
                },
                "pending": {
                    "description": "Set to `true` if the `Http2Stream` instance has not yet been assigned a\nnumeric stream identifier.",
                    "type": "boolean"
                },
                "pushAllowed": {
                    "description": "Read-only property mapped to the `SETTINGS_ENABLE_PUSH` flag of the remote\nclient's most recent `SETTINGS` frame. Will be `true` if the remote peer\naccepts push streams, `false` otherwise. Settings are the same for every`Http2Stream` in the same `Http2Session`.",
                    "type": "boolean"
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "rstCode": {
                    "description": "Set to the `RST_STREAM` `error code` reported when the `Http2Stream` is\ndestroyed after either receiving an `RST_STREAM` frame from the connected peer,\ncalling `http2stream.close()`, or `http2stream.destroy()`. Will be`undefined` if the `Http2Stream` has not been closed.",
                    "type": "number"
                },
                "sentHeaders": {
                    "$ref": "#/definitions/OutgoingHttpHeaders",
                    "description": "An object containing the outbound headers sent for this `Http2Stream`."
                },
                "sentInfoHeaders": {
                    "description": "An array of objects containing the outbound informational (additional) headers\nsent for this `Http2Stream`.",
                    "items": {
                        "$ref": "#/definitions/OutgoingHttpHeaders"
                    },
                    "type": "array"
                },
                "sentTrailers": {
                    "$ref": "#/definitions/OutgoingHttpHeaders",
                    "description": "An object containing the outbound trailers sent for this `HttpStream`."
                },
                "session": {
                    "$ref": "#/definitions/Http2Session",
                    "description": "A reference to the `Http2Session` instance that owns this `Http2Stream`. The\nvalue will be `undefined` after the `Http2Stream` instance is destroyed."
                },
                "state": {
                    "$ref": "#/definitions/StreamState",
                    "description": "Provides miscellaneous information about the current state of the`Http2Stream`.\n\nA current state of this `Http2Stream`."
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "aborted",
                "allowHalfOpen",
                "bufferSize",
                "closed",
                "destroyed",
                "endAfterHeaders",
                "errored",
                "headersSent",
                "pending",
                "pushAllowed",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "rstCode",
                "sentHeaders",
                "session",
                "state",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "ServerOptions": {
            "additionalProperties": false,
            "properties": {
                "Http1IncomingMessage": {
                    "additionalProperties": false,
                    "description": "An `IncomingMessage` object is created by {@link Server} or {@link ClientRequest} and passed as the first argument to the `'request'` and `'response'` event respectively. It may be used to\naccess response\nstatus, headers and data.\n\nDifferent from its `socket` value which is a subclass of `stream.Duplex`, the`IncomingMessage` itself extends `stream.Readable` and is created separately to\nparse and emit the incoming HTTP headers and payload, as the underlying socket\nmay be reused multiple times in case of keep-alive.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/IncomingMessage"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "Http1ServerResponse": {
                    "additionalProperties": false,
                    "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/ServerResponse<any>"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "Http2ServerRequest": {
                    "additionalProperties": false,
                    "description": "A `Http2ServerRequest` object is created by {@link Server} or {@link SecureServer} and passed as the first argument to the `'request'` event. It may be used to access a request status,\nheaders, and\ndata.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/Http2ServerRequest"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "Http2ServerResponse": {
                    "additionalProperties": false,
                    "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/Http2ServerResponse"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "maxDeflateDynamicTableSize": {
                    "type": "number"
                },
                "maxHeaderListPairs": {
                    "type": "number"
                },
                "maxOutstandingPings": {
                    "type": "number"
                },
                "maxSendHeaderBlockLength": {
                    "type": "number"
                },
                "maxSessionMemory": {
                    "type": "number"
                },
                "paddingStrategy": {
                    "type": "number"
                },
                "peerMaxConcurrentStreams": {
                    "type": "number"
                },
                "settings": {
                    "$ref": "#/definitions/Settings"
                },
                "unknownProtocolTimeout": {
                    "default": 100000,
                    "description": "Specifies a timeout in milliseconds that\na server should wait when an [`'unknownProtocol'`][] is emitted. If the\nsocket has not been destroyed by that time the server will destroy it.",
                    "type": "number"
                }
            },
            "type": "object"
        },
        "ServerOptions<typeofIncomingMessage,typeofServerResponse>": {
            "additionalProperties": false,
            "properties": {
                "IncomingMessage": {
                    "additionalProperties": false,
                    "description": "An `IncomingMessage` object is created by {@link Server} or {@link ClientRequest} and passed as the first argument to the `'request'` and `'response'` event respectively. It may be used to\naccess response\nstatus, headers and data.\n\nDifferent from its `socket` value which is a subclass of `stream.Duplex`, the`IncomingMessage` itself extends `stream.Readable` and is created separately to\nparse and emit the incoming HTTP headers and payload, as the underlying socket\nmay be reused multiple times in case of keep-alive.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/IncomingMessage"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "ServerResponse": {
                    "additionalProperties": false,
                    "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/ServerResponse<any>"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "connectionsCheckingInterval": {
                    "default": 30000,
                    "description": "Sets the interval value in milliseconds to check for request and headers timeout in incomplete requests.",
                    "type": "number"
                },
                "insecureHTTPParser": {
                    "default": false,
                    "description": "Use an insecure HTTP parser that accepts invalid HTTP headers when `true`.\nUsing the insecure parser should be avoided.\nSee --insecure-http-parser for more information.",
                    "type": "boolean"
                },
                "keepAlive": {
                    "default": false,
                    "description": "If set to `true`, it enables keep-alive functionality on the socket immediately after a new incoming connection is received,\nsimilarly on what is done in `socket.setKeepAlive([enable][, initialDelay])`.",
                    "type": "boolean"
                },
                "keepAliveInitialDelay": {
                    "default": 0,
                    "description": "If set to a positive number, it sets the initial delay before the first keepalive probe is sent on an idle socket.",
                    "type": "number"
                },
                "keepAliveTimeout": {
                    "default": 5000,
                    "description": "The number of milliseconds of inactivity a server needs to wait for additional incoming data,\nafter it has finished writing the last response, before a socket will be destroyed.",
                    "type": "number"
                },
                "maxHeaderSize": {
                    "default": 16384,
                    "description": "Optionally overrides the value of\n`--max-http-header-size` for requests received by this server, i.e.\nthe maximum length of request headers in bytes.",
                    "type": "number"
                },
                "noDelay": {
                    "default": true,
                    "description": "If set to `true`, it disables the use of Nagle's algorithm immediately after a new incoming connection is received.",
                    "type": "boolean"
                },
                "requestTimeout": {
                    "default": 300000,
                    "description": "Sets the timeout value in milliseconds for receiving the entire request from the client.",
                    "type": "number"
                },
                "uniqueHeaders": {
                    "description": "A list of response headers that should be sent only once.\nIf the header's value is an array, the items will be joined using `; `.",
                    "items": {
                        "anyOf": [
                            {
                                "items": {
                                    "type": "string"
                                },
                                "type": "array"
                            },
                            {
                                "type": "string"
                            }
                        ]
                    },
                    "type": "array"
                }
            },
            "type": "object"
        },
        "ServerOptions<typeofIncomingMessage,typeofServerResponse>_1": {
            "additionalProperties": false,
            "properties": {
                "ALPNProtocols": {
                    "anyOf": [
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        },
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "additionalProperties": false,
                                "patternProperties": {
                                    "^[0-9]+$": {
                                        "type": "number"
                                    }
                                },
                                "type": "object"
                            },
                            "type": "array"
                        }
                    ],
                    "description": "An array of strings or a Buffer naming possible ALPN protocols.\n(Protocols should be ordered by their priority.)"
                },
                "IncomingMessage": {
                    "additionalProperties": false,
                    "description": "An `IncomingMessage` object is created by {@link Server} or {@link ClientRequest} and passed as the first argument to the `'request'` and `'response'` event respectively. It may be used to\naccess response\nstatus, headers and data.\n\nDifferent from its `socket` value which is a subclass of `stream.Duplex`, the`IncomingMessage` itself extends `stream.Readable` and is created separately to\nparse and emit the incoming HTTP headers and payload, as the underlying socket\nmay be reused multiple times in case of keep-alive.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/IncomingMessage"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "SNICallback": {
                    "additionalProperties": false,
                    "description": "SNICallback(servername, cb) <Function> A function that will be\ncalled if the client supports SNI TLS extension. Two arguments\nwill be passed when called: servername and cb. SNICallback should\ninvoke cb(null, ctx), where ctx is a SecureContext instance.\n(tls.createSecureContext(...) can be used to get a proper\nSecureContext.) If SNICallback wasn't provided the default callback\nwith high-level API will be used (see below).",
                    "type": "object"
                },
                "ServerResponse": {
                    "additionalProperties": false,
                    "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
                    "properties": {
                        "Duplex": {
                            "$ref": "#/definitions/typeofDuplex",
                            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                        },
                        "EventEmitter": {
                            "$ref": "#/definitions/typeofimport(\"events\")",
                            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                        },
                        "PassThrough": {
                            "$ref": "#/definitions/typeofPassThrough",
                            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                        },
                        "Readable": {
                            "$ref": "#/definitions/typeofReadable"
                        },
                        "Stream": {
                            "$ref": "#/definitions/typeofStream"
                        },
                        "Transform": {
                            "$ref": "#/definitions/typeofTransform",
                            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                        },
                        "Writable": {
                            "$ref": "#/definitions/typeofWritable"
                        },
                        "addAbortSignal": {
                            "additionalProperties": false,
                            "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                            "type": "object"
                        },
                        "captureRejectionSymbol": {
                            "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                        },
                        "captureRejections": {
                            "description": "Sets or gets the default captureRejection value for all emitters.",
                            "type": "boolean"
                        },
                        "consumers": {
                            "additionalProperties": false,
                            "properties": {
                                "arrayBuffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "blob": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "buffer": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "json": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "text": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "arrayBuffer",
                                "blob",
                                "buffer",
                                "json",
                                "text"
                            ],
                            "type": "object"
                        },
                        "defaultMaxListeners": {
                            "type": "number"
                        },
                        "errorMonitor": {
                            "$ref": "#/definitions/typeoferrorMonitor",
                            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                        },
                        "finished": {
                            "additionalProperties": false,
                            "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "isErrored": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream has encountered an error.",
                            "type": "object"
                        },
                        "isReadable": {
                            "additionalProperties": false,
                            "description": "Returns whether the stream is readable.",
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                            "properties": {
                                "__promisify__": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "__promisify__"
                            ],
                            "type": "object"
                        },
                        "promises": {
                            "additionalProperties": false,
                            "properties": {
                                "finished": {
                                    "additionalProperties": false,
                                    "type": "object"
                                },
                                "pipeline": {
                                    "additionalProperties": false,
                                    "type": "object"
                                }
                            },
                            "required": [
                                "finished",
                                "pipeline"
                            ],
                            "type": "object"
                        },
                        "prototype": {
                            "$ref": "#/definitions/ServerResponse<any>"
                        }
                    },
                    "required": [
                        "Duplex",
                        "EventEmitter",
                        "PassThrough",
                        "Readable",
                        "Stream",
                        "Transform",
                        "Writable",
                        "addAbortSignal",
                        "captureRejectionSymbol",
                        "captureRejections",
                        "consumers",
                        "defaultMaxListeners",
                        "errorMonitor",
                        "finished",
                        "isErrored",
                        "isReadable",
                        "pipeline",
                        "promises",
                        "prototype"
                    ],
                    "type": "object"
                },
                "allowHalfOpen": {
                    "default": false,
                    "description": "Indicates whether half-opened TCP connections are allowed.",
                    "type": "boolean"
                },
                "ca": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "anyOf": [
                                    {
                                        "additionalProperties": false,
                                        "patternProperties": {
                                            "^[0-9]+$": {
                                                "type": "number"
                                            }
                                        },
                                        "type": "object"
                                    },
                                    {
                                        "type": "string"
                                    }
                                ]
                            },
                            "type": "array"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "Optionally override the trusted CA certificates. Default is to trust\nthe well-known CAs curated by Mozilla. Mozilla's CAs are completely\nreplaced when CAs are explicitly specified using this option."
                },
                "cert": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "anyOf": [
                                    {
                                        "additionalProperties": false,
                                        "patternProperties": {
                                            "^[0-9]+$": {
                                                "type": "number"
                                            }
                                        },
                                        "type": "object"
                                    },
                                    {
                                        "type": "string"
                                    }
                                ]
                            },
                            "type": "array"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "Cert chains in PEM format. One cert chain should be provided per\nprivate key. Each cert chain should consist of the PEM formatted\ncertificate for a provided private key, followed by the PEM\nformatted intermediate certificates (if any), in order, and not\nincluding the root CA (the root CA must be pre-known to the peer,\nsee ca). When providing multiple cert chains, they do not have to\nbe in the same order as their private keys in key. If the\nintermediate certificates are not provided, the peer will not be\nable to validate the certificate, and the handshake will fail."
                },
                "ciphers": {
                    "description": "Cipher suite specification, replacing the default. For more\ninformation, see modifying the default cipher suite. Permitted\nciphers can be obtained via tls.getCiphers(). Cipher names must be\nuppercased in order for OpenSSL to accept them.",
                    "type": "string"
                },
                "clientCertEngine": {
                    "description": "Name of an OpenSSL engine which can provide the client certificate.",
                    "type": "string"
                },
                "connectionsCheckingInterval": {
                    "default": 30000,
                    "description": "Sets the interval value in milliseconds to check for request and headers timeout in incomplete requests.",
                    "type": "number"
                },
                "crl": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "anyOf": [
                                    {
                                        "additionalProperties": false,
                                        "patternProperties": {
                                            "^[0-9]+$": {
                                                "type": "number"
                                            }
                                        },
                                        "type": "object"
                                    },
                                    {
                                        "type": "string"
                                    }
                                ]
                            },
                            "type": "array"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "PEM formatted CRLs (Certificate Revocation Lists)."
                },
                "dhparam": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "Diffie Hellman parameters, required for Perfect Forward Secrecy. Use\nopenssl dhparam to create the parameters. The key length must be\ngreater than or equal to 1024 bits or else an error will be thrown.\nAlthough 1024 bits is permissible, use 2048 bits or larger for\nstronger security. If omitted or invalid, the parameters are\nsilently discarded and DHE ciphers will not be available."
                },
                "ecdhCurve": {
                    "description": "A string describing a named curve or a colon separated list of curve\nNIDs or names, for example P-521:P-384:P-256, to use for ECDH key\nagreement. Set to auto to select the curve automatically. Use\ncrypto.getCurves() to obtain a list of available curve names. On\nrecent releases, openssl ecparam -list_curves will also display the\nname and description of each available elliptic curve. Default:\ntls.DEFAULT_ECDH_CURVE.",
                    "type": "string"
                },
                "enableTrace": {
                    "default": false,
                    "description": "When enabled, TLS packet trace information is written to `stderr`. This can be\nused to debug TLS connection problems.",
                    "type": "boolean"
                },
                "handshakeTimeout": {
                    "description": "Abort the connection if the SSL/TLS handshake does not finish in the\nspecified number of milliseconds. A 'tlsClientError' is emitted on\nthe tls.Server object whenever a handshake times out. Default:\n120000 (120 seconds).",
                    "type": "number"
                },
                "honorCipherOrder": {
                    "description": "Attempt to use the server's cipher suite preferences instead of the\nclient's. When true, causes SSL_OP_CIPHER_SERVER_PREFERENCE to be\nset in secureOptions",
                    "type": "boolean"
                },
                "insecureHTTPParser": {
                    "default": false,
                    "description": "Use an insecure HTTP parser that accepts invalid HTTP headers when `true`.\nUsing the insecure parser should be avoided.\nSee --insecure-http-parser for more information.",
                    "type": "boolean"
                },
                "keepAlive": {
                    "default": false,
                    "description": "If set to `true`, it enables keep-alive functionality on the socket immediately after a new incoming connection is received,\nsimilarly on what is done in `socket.setKeepAlive([enable][, initialDelay])`.",
                    "type": "boolean"
                },
                "keepAliveInitialDelay": {
                    "default": 0,
                    "description": "If set to a positive number, it sets the initial delay before the first keepalive probe is sent on an idle socket.",
                    "type": "number"
                },
                "keepAliveTimeout": {
                    "default": 5000,
                    "description": "The number of milliseconds of inactivity a server needs to wait for additional incoming data,\nafter it has finished writing the last response, before a socket will be destroyed.",
                    "type": "number"
                },
                "key": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "anyOf": [
                                    {
                                        "additionalProperties": false,
                                        "patternProperties": {
                                            "^[0-9]+$": {
                                                "type": "number"
                                            }
                                        },
                                        "type": "object"
                                    },
                                    {
                                        "$ref": "#/definitions/KeyObject"
                                    },
                                    {
                                        "type": "string"
                                    }
                                ]
                            },
                            "type": "array"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "Private keys in PEM format. PEM allows the option of private keys\nbeing encrypted. Encrypted keys will be decrypted with\noptions.passphrase. Multiple keys using different algorithms can be\nprovided either as an array of unencrypted key strings or buffers,\nor an array of objects in the form {pem: <string|buffer>[,\npassphrase: <string>]}. The object form can only occur in an array.\nobject.passphrase is optional. Encrypted keys will be decrypted with\nobject.passphrase if provided, or options.passphrase if it is not."
                },
                "maxHeaderSize": {
                    "default": 16384,
                    "description": "Optionally overrides the value of\n`--max-http-header-size` for requests received by this server, i.e.\nthe maximum length of request headers in bytes.",
                    "type": "number"
                },
                "maxVersion": {
                    "description": "Optionally set the maximum TLS version to allow. One\nof `'TLSv1.3'`, `'TLSv1.2'`, `'TLSv1.1'`, or `'TLSv1'`. Cannot be specified along with the\n`secureProtocol` option, use one or the other.\n**Default:** `'TLSv1.3'`, unless changed using CLI options. Using\n`--tls-max-v1.2` sets the default to `'TLSv1.2'`. Using `--tls-max-v1.3` sets the default to\n`'TLSv1.3'`. If multiple of the options are provided, the highest maximum is used.",
                    "enum": [
                        "TLSv1",
                        "TLSv1.1",
                        "TLSv1.2",
                        "TLSv1.3"
                    ],
                    "type": "string"
                },
                "minVersion": {
                    "description": "Optionally set the minimum TLS version to allow. One\nof `'TLSv1.3'`, `'TLSv1.2'`, `'TLSv1.1'`, or `'TLSv1'`. Cannot be specified along with the\n`secureProtocol` option, use one or the other.  It is not recommended to use\nless than TLSv1.2, but it may be required for interoperability.\n**Default:** `'TLSv1.2'`, unless changed using CLI options. Using\n`--tls-v1.0` sets the default to `'TLSv1'`. Using `--tls-v1.1` sets the default to\n`'TLSv1.1'`. Using `--tls-min-v1.3` sets the default to\n'TLSv1.3'. If multiple of the options are provided, the lowest minimum is used.",
                    "enum": [
                        "TLSv1",
                        "TLSv1.1",
                        "TLSv1.2",
                        "TLSv1.3"
                    ],
                    "type": "string"
                },
                "noDelay": {
                    "default": true,
                    "description": "If set to `true`, it disables the use of Nagle's algorithm immediately after a new incoming connection is received.",
                    "type": "boolean"
                },
                "passphrase": {
                    "description": "Shared passphrase used for a single private key and/or a PFX.",
                    "type": "string"
                },
                "pauseOnConnect": {
                    "default": false,
                    "description": "Indicates whether the socket should be paused on incoming connections.",
                    "type": "boolean"
                },
                "pfx": {
                    "anyOf": [
                        {
                            "additionalProperties": false,
                            "patternProperties": {
                                "^[0-9]+$": {
                                    "type": "number"
                                }
                            },
                            "type": "object"
                        },
                        {
                            "items": {
                                "anyOf": [
                                    {
                                        "additionalProperties": false,
                                        "patternProperties": {
                                            "^[0-9]+$": {
                                                "type": "number"
                                            }
                                        },
                                        "type": "object"
                                    },
                                    {
                                        "$ref": "#/definitions/PxfObject"
                                    },
                                    {
                                        "type": "string"
                                    }
                                ]
                            },
                            "type": "array"
                        },
                        {
                            "type": "string"
                        }
                    ],
                    "description": "PFX or PKCS12 encoded private key and certificate chain. pfx is an\nalternative to providing key and cert individually. PFX is usually\nencrypted, if it is, passphrase will be used to decrypt it. Multiple\nPFX can be provided either as an array of unencrypted PFX buffers,\nor an array of objects in the form {buf: <string|buffer>[,\npassphrase: <string>]}. The object form can only occur in an array.\nobject.passphrase is optional. Encrypted PFX will be decrypted with\nobject.passphrase if provided, or options.passphrase if it is not."
                },
                "privateKeyEngine": {
                    "description": "Name of an OpenSSL engine to get private key from. Should be used\ntogether with privateKeyIdentifier.",
                    "type": "string"
                },
                "privateKeyIdentifier": {
                    "description": "Identifier of a private key managed by an OpenSSL engine. Should be\nused together with privateKeyEngine. Should not be set together with\nkey, because both options define a private key in different ways.",
                    "type": "string"
                },
                "pskIdentityHint": {
                    "description": "hint to send to a client to help\nwith selecting the identity during TLS-PSK negotiation. Will be ignored\nin TLS 1.3. Upon failing to set pskIdentityHint `tlsClientError` will be\nemitted with `ERR_TLS_PSK_SET_IDENTIY_HINT_FAILED` code.",
                    "type": "string"
                },
                "rejectUnauthorized": {
                    "default": true,
                    "description": "If true the server will reject any connection which is not\nauthorized with the list of supplied CAs. This option only has an\neffect if requestCert is true.",
                    "type": "boolean"
                },
                "requestCert": {
                    "description": "If true the server will request a certificate from clients that\nconnect and attempt to verify that certificate. Defaults to\nfalse.",
                    "type": "boolean"
                },
                "requestTimeout": {
                    "default": 300000,
                    "description": "Sets the timeout value in milliseconds for receiving the entire request from the client.",
                    "type": "number"
                },
                "secureContext": {
                    "$ref": "#/definitions/SecureContext",
                    "description": "An optional TLS context object from tls.createSecureContext()"
                },
                "secureOptions": {
                    "description": "Optionally affect the OpenSSL protocol behavior, which is not\nusually necessary. This should be used carefully if at all! Value is\na numeric bitmask of the SSL_OP_* options from OpenSSL Options",
                    "type": "number"
                },
                "secureProtocol": {
                    "description": "Legacy mechanism to select the TLS protocol version to use, it does\nnot support independent control of the minimum and maximum version,\nand does not support limiting the protocol to TLSv1.3. Use\nminVersion and maxVersion instead. The possible values are listed as\nSSL_METHODS, use the function names as strings. For example, use\n'TLSv1_1_method' to force TLS version 1.1, or 'TLS_method' to allow\nany TLS protocol version up to TLSv1.3. It is not recommended to use\nTLS versions less than 1.2, but it may be required for\ninteroperability. Default: none, see minVersion.",
                    "type": "string"
                },
                "sessionIdContext": {
                    "description": "Opaque identifier used by servers to ensure session state is not\nshared between applications. Unused by clients.",
                    "type": "string"
                },
                "sessionTimeout": {
                    "description": "The number of seconds after which a TLS session created by the\nserver will no longer be resumable. See Session Resumption for more\ninformation. Default: 300.",
                    "type": "number"
                },
                "sigalgs": {
                    "description": "Colon-separated list of supported signature algorithms. The list\ncan contain digest algorithms (SHA256, MD5 etc.), public key\nalgorithms (RSA-PSS, ECDSA etc.), combination of both (e.g\n'RSA+SHA384') or TLS v1.3 scheme names (e.g. rsa_pss_pss_sha512).",
                    "type": "string"
                },
                "ticketKeys": {
                    "additionalProperties": false,
                    "description": "48-bytes of cryptographically strong pseudo-random data.",
                    "patternProperties": {
                        "^[0-9]+$": {
                            "type": "number"
                        }
                    },
                    "type": "object"
                },
                "uniqueHeaders": {
                    "description": "A list of response headers that should be sent only once.\nIf the header's value is an array, the items will be joined using `; `.",
                    "items": {
                        "anyOf": [
                            {
                                "items": {
                                    "type": "string"
                                },
                                "type": "array"
                            },
                            {
                                "type": "string"
                            }
                        ]
                    },
                    "type": "array"
                }
            },
            "type": "object"
        },
        "ServerResponse<any>": {
            "additionalProperties": false,
            "description": "This object is created internally by an HTTP server, not by the user. It is\npassed as the second parameter to the `'request'` event.",
            "properties": {
                "chunkedEncoding": {
                    "type": "boolean"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "connection": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Aliases of `outgoingMessage.socket`"
                },
                "destroyed": {
                    "description": "Is `true` after `writable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "finished": {
                    "type": "boolean"
                },
                "headersSent": {
                    "description": "Read-only. `true` if the headers were sent, otherwise `false`.",
                    "type": "boolean"
                },
                "req": {},
                "sendDate": {
                    "type": "boolean"
                },
                "shouldKeepAlive": {
                    "type": "boolean"
                },
                "socket": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Socket"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Reference to the underlying socket. Usually, users will not want to access\nthis property.\n\nAfter calling `outgoingMessage.end()`, this property will be nulled."
                },
                "statusCode": {
                    "description": "When using implicit headers (not calling `response.writeHead()` explicitly),\nthis property controls the status code that will be sent to the client when\nthe headers get flushed.\n\n```js\nresponse.statusCode = 404;\n```\n\nAfter response header was sent to the client, this property indicates the\nstatus code which was sent out.",
                    "type": "number"
                },
                "statusMessage": {
                    "description": "When using implicit headers (not calling `response.writeHead()` explicitly),\nthis property controls the status message that will be sent to the client when\nthe headers get flushed. If this is left as `undefined` then the standard\nmessage for the status code will be used.\n\n```js\nresponse.statusMessage = 'Not found';\n```\n\nAfter response header was sent to the client, this property indicates the\nstatus message which was sent out.",
                    "type": "string"
                },
                "useChunkedEncodingByDefault": {
                    "type": "boolean"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "chunkedEncoding",
                "closed",
                "connection",
                "destroyed",
                "errored",
                "finished",
                "headersSent",
                "req",
                "sendDate",
                "shouldKeepAlive",
                "socket",
                "statusCode",
                "statusMessage",
                "useChunkedEncodingByDefault",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "SessionState": {
            "additionalProperties": false,
            "properties": {
                "deflateDynamicTableSize": {
                    "type": "number"
                },
                "effectiveLocalWindowSize": {
                    "type": "number"
                },
                "effectiveRecvDataLength": {
                    "type": "number"
                },
                "inflateDynamicTableSize": {
                    "type": "number"
                },
                "lastProcStreamID": {
                    "type": "number"
                },
                "localWindowSize": {
                    "type": "number"
                },
                "nextStreamID": {
                    "type": "number"
                },
                "outboundQueueSize": {
                    "type": "number"
                },
                "remoteWindowSize": {
                    "type": "number"
                }
            },
            "type": "object"
        },
        "Settings": {
            "additionalProperties": false,
            "properties": {
                "enableConnectProtocol": {
                    "type": "boolean"
                },
                "enablePush": {
                    "type": "boolean"
                },
                "headerTableSize": {
                    "type": "number"
                },
                "initialWindowSize": {
                    "type": "number"
                },
                "maxConcurrentStreams": {
                    "type": "number"
                },
                "maxFrameSize": {
                    "type": "number"
                },
                "maxHeaderListSize": {
                    "type": "number"
                }
            },
            "type": "object"
        },
        "Socket": {
            "additionalProperties": false,
            "description": "This class is an abstraction of a TCP socket or a streaming `IPC` endpoint\n(uses named pipes on Windows, and Unix domain sockets otherwise). It is also\nan `EventEmitter`.\n\nA `net.Socket` can be created by the user and used directly to interact with\na server. For example, it is returned by {@link createConnection},\nso the user can use it to talk to the server.\n\nIt can also be created by Node.js and passed to the user when a connection\nis received. For example, it is passed to the listeners of a `'connection'` event emitted on a {@link Server}, so the user can use\nit to interact with the client.",
            "properties": {
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "bufferSize": {
                    "description": "This property shows the number of characters buffered for writing. The buffer\nmay contain strings whose length after encoding is not yet known. So this number\nis only an approximation of the number of bytes in the buffer.\n\n`net.Socket` has the property that `socket.write()` always works. This is to\nhelp users get up and running quickly. The computer cannot always keep up\nwith the amount of data that is written to a socket. The network connection\nsimply might be too slow. Node.js will internally queue up the data written to a\nsocket and send it out over the wire when it is possible.\n\nThe consequence of this internal buffering is that memory may grow.\nUsers who experience large or growing `bufferSize` should attempt to\n\"throttle\" the data flows in their program with `socket.pause()` and `socket.resume()`.",
                    "type": "number"
                },
                "bytesRead": {
                    "description": "The amount of received bytes.",
                    "type": "number"
                },
                "bytesWritten": {
                    "description": "The amount of bytes sent.",
                    "type": "number"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "connecting": {
                    "description": "If `true`,`socket.connect(options[, connectListener])` was\ncalled and has not yet finished. It will stay `true` until the socket becomes\nconnected, then it is set to `false` and the `'connect'` event is emitted. Note\nthat the `socket.connect(options[, connectListener])` callback is a listener for the `'connect'` event.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "See `writable.destroyed` for further details.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "localAddress": {
                    "description": "The string representation of the local IP address the remote client is\nconnecting on. For example, in a server listening on `'0.0.0.0'`, if a client\nconnects on `'192.168.1.1'`, the value of `socket.localAddress` would be`'192.168.1.1'`.",
                    "type": "string"
                },
                "localFamily": {
                    "description": "The string representation of the local IP family. `'IPv4'` or `'IPv6'`.",
                    "type": "string"
                },
                "localPort": {
                    "description": "The numeric representation of the local port. For example, `80` or `21`.",
                    "type": "number"
                },
                "pending": {
                    "description": "This is `true` if the socket is not connected yet, either because `.connect()`\nhas not yet been called or because it is still in the process of connecting (see `socket.connecting`).",
                    "type": "boolean"
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "readyState": {
                    "$ref": "#/definitions/SocketReadyState",
                    "description": "This property represents the state of the connection as a string."
                },
                "remoteAddress": {
                    "description": "The string representation of the remote IP address. For example,`'74.125.127.100'` or `'2001:4860:a005::68'`. Value may be `undefined` if\nthe socket is destroyed (for example, if the client disconnected).",
                    "type": "string"
                },
                "remoteFamily": {
                    "description": "The string representation of the remote IP family. `'IPv4'` or `'IPv6'`.",
                    "type": "string"
                },
                "remotePort": {
                    "description": "The numeric representation of the remote port. For example, `80` or `21`.",
                    "type": "number"
                },
                "timeout": {
                    "description": "The socket timeout in milliseconds as set by socket.setTimeout(). It is undefined if a timeout has not been set.",
                    "type": "number"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "allowHalfOpen",
                "bufferSize",
                "bytesRead",
                "bytesWritten",
                "closed",
                "connecting",
                "destroyed",
                "errored",
                "pending",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "readyState",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "SocketReadyState": {
            "enum": [
                "closed",
                "open",
                "opening",
                "readOnly",
                "writeOnly"
            ],
            "type": "string"
        },
        "Stream": {
            "additionalProperties": false,
            "type": "object"
        },
        "StreamState": {
            "additionalProperties": false,
            "properties": {
                "localClose": {
                    "type": "number"
                },
                "localWindowSize": {
                    "type": "number"
                },
                "remoteClose": {
                    "type": "number"
                },
                "state": {
                    "type": "number"
                },
                "sumDependencyWeight": {
                    "type": "number"
                },
                "weight": {
                    "type": "number"
                }
            },
            "type": "object"
        },
        "T": {
            "additionalProperties": false,
            "type": "object"
        },
        "TLSSocket": {
            "additionalProperties": false,
            "description": "Performs transparent encryption of written data and all required TLS\nnegotiation.\n\nInstances of `tls.TLSSocket` implement the duplex `Stream` interface.\n\nMethods that return TLS connection metadata (e.g.{@link TLSSocket.getPeerCertificate} will only return data while the\nconnection is open.",
            "properties": {
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "alpnProtocol": {
                    "anyOf": [
                        {
                            "enum": [
                                false
                            ],
                            "type": "boolean"
                        },
                        {
                            "type": [
                                "null",
                                "string"
                            ]
                        }
                    ],
                    "description": "String containing the selected ALPN protocol.\nBefore a handshake has completed, this value is always null.\nWhen a handshake is completed but not ALPN protocol was selected, tlsSocket.alpnProtocol equals false."
                },
                "authorizationError": {
                    "$ref": "#/definitions/Error",
                    "description": "Returns the reason why the peer's certificate was not been verified. This\nproperty is set only when `tlsSocket.authorized === false`."
                },
                "authorized": {
                    "description": "This property is `true` if the peer certificate was signed by one of the CAs\nspecified when creating the `tls.TLSSocket` instance, otherwise `false`.",
                    "type": "boolean"
                },
                "bufferSize": {
                    "description": "This property shows the number of characters buffered for writing. The buffer\nmay contain strings whose length after encoding is not yet known. So this number\nis only an approximation of the number of bytes in the buffer.\n\n`net.Socket` has the property that `socket.write()` always works. This is to\nhelp users get up and running quickly. The computer cannot always keep up\nwith the amount of data that is written to a socket. The network connection\nsimply might be too slow. Node.js will internally queue up the data written to a\nsocket and send it out over the wire when it is possible.\n\nThe consequence of this internal buffering is that memory may grow.\nUsers who experience large or growing `bufferSize` should attempt to\n\"throttle\" the data flows in their program with `socket.pause()` and `socket.resume()`.",
                    "type": "number"
                },
                "bytesRead": {
                    "description": "The amount of received bytes.",
                    "type": "number"
                },
                "bytesWritten": {
                    "description": "The amount of bytes sent.",
                    "type": "number"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "connecting": {
                    "description": "If `true`,`socket.connect(options[, connectListener])` was\ncalled and has not yet finished. It will stay `true` until the socket becomes\nconnected, then it is set to `false` and the `'connect'` event is emitted. Note\nthat the `socket.connect(options[, connectListener])` callback is a listener for the `'connect'` event.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "See `writable.destroyed` for further details.",
                    "type": "boolean"
                },
                "encrypted": {
                    "description": "Always returns `true`. This may be used to distinguish TLS sockets from regular`net.Socket` instances.",
                    "enum": [
                        true
                    ],
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "localAddress": {
                    "description": "The string representation of the local IP address the remote client is\nconnecting on. For example, in a server listening on `'0.0.0.0'`, if a client\nconnects on `'192.168.1.1'`, the value of `socket.localAddress` would be`'192.168.1.1'`.",
                    "type": "string"
                },
                "localFamily": {
                    "description": "The string representation of the local IP family. `'IPv4'` or `'IPv6'`.",
                    "type": "string"
                },
                "localPort": {
                    "description": "The numeric representation of the local port. For example, `80` or `21`.",
                    "type": "number"
                },
                "pending": {
                    "description": "This is `true` if the socket is not connected yet, either because `.connect()`\nhas not yet been called or because it is still in the process of connecting (see `socket.connecting`).",
                    "type": "boolean"
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "readyState": {
                    "$ref": "#/definitions/SocketReadyState",
                    "description": "This property represents the state of the connection as a string."
                },
                "remoteAddress": {
                    "description": "The string representation of the remote IP address. For example,`'74.125.127.100'` or `'2001:4860:a005::68'`. Value may be `undefined` if\nthe socket is destroyed (for example, if the client disconnected).",
                    "type": "string"
                },
                "remoteFamily": {
                    "description": "The string representation of the remote IP family. `'IPv4'` or `'IPv6'`.",
                    "type": "string"
                },
                "remotePort": {
                    "description": "The numeric representation of the remote port. For example, `80` or `21`.",
                    "type": "number"
                },
                "timeout": {
                    "description": "The socket timeout in milliseconds as set by socket.setTimeout(). It is undefined if a timeout has not been set.",
                    "type": "number"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "allowHalfOpen",
                "alpnProtocol",
                "authorizationError",
                "authorized",
                "bufferSize",
                "bytesRead",
                "bytesWritten",
                "closed",
                "connecting",
                "destroyed",
                "encrypted",
                "errored",
                "pending",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "readyState",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "Transform": {
            "additionalProperties": false,
            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`",
            "properties": {
                "allowHalfOpen": {
                    "description": "If `false` then the stream will automatically end the writable side when the\nreadable side ends. Set initially by the `allowHalfOpen` constructor option,\nwhich defaults to `false`.\n\nThis can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is\nemitted.",
                    "type": "boolean"
                },
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Is `true` after `readable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "readable": {
                    "description": "Is `true` if it is safe to call `readable.read()`, which means\nthe stream has not been destroyed or emitted `'error'` or `'end'`.",
                    "type": "boolean"
                },
                "readableAborted": {
                    "description": "Returns whether the stream was destroyed or errored before emitting `'end'`.",
                    "type": "boolean"
                },
                "readableDidRead": {
                    "description": "Returns whether `'data'` has been emitted.",
                    "type": "boolean"
                },
                "readableEncoding": {
                    "anyOf": [
                        {
                            "enum": [
                                "ascii",
                                "base64",
                                "base64url",
                                "binary",
                                "hex",
                                "latin1",
                                "ucs-2",
                                "ucs2",
                                "utf-8",
                                "utf16le",
                                "utf8"
                            ],
                            "type": "string"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method."
                },
                "readableEnded": {
                    "description": "Becomes `true` when `'end'` event is emitted.",
                    "type": "boolean"
                },
                "readableFlowing": {
                    "description": "This property reflects the current state of a `Readable` stream as described\nin the `Three states` section.",
                    "type": [
                        "null",
                        "boolean"
                    ]
                },
                "readableHighWaterMark": {
                    "description": "Returns the value of `highWaterMark` passed when creating this `Readable`.",
                    "type": "number"
                },
                "readableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be read. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "readableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Readable` stream.",
                    "type": "boolean"
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "allowHalfOpen",
                "closed",
                "destroyed",
                "errored",
                "readable",
                "readableAborted",
                "readableDidRead",
                "readableEncoding",
                "readableEnded",
                "readableFlowing",
                "readableHighWaterMark",
                "readableLength",
                "readableObjectMode",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "Writable": {
            "additionalProperties": false,
            "properties": {
                "closed": {
                    "description": "Is true after 'close' has been emitted.",
                    "type": "boolean"
                },
                "destroyed": {
                    "description": "Is `true` after `writable.destroy()` has been called.",
                    "type": "boolean"
                },
                "errored": {
                    "anyOf": [
                        {
                            "$ref": "#/definitions/Error"
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "description": "Returns error if the stream has been destroyed with an error."
                },
                "writable": {
                    "description": "Is `true` if it is safe to call `writable.write()`, which means\nthe stream has not been destroyed, errored or ended.",
                    "type": "boolean"
                },
                "writableCorked": {
                    "description": "Number of times `writable.uncork()` needs to be\ncalled in order to fully uncork the stream.",
                    "type": "number"
                },
                "writableEnded": {
                    "description": "Is `true` after `writable.end()` has been called. This property\ndoes not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.",
                    "type": "boolean"
                },
                "writableFinished": {
                    "description": "Is set to `true` immediately before the `'finish'` event is emitted.",
                    "type": "boolean"
                },
                "writableHighWaterMark": {
                    "description": "Return the value of `highWaterMark` passed when creating this `Writable`.",
                    "type": "number"
                },
                "writableLength": {
                    "description": "This property contains the number of bytes (or objects) in the queue\nready to be written. The value provides introspection data regarding\nthe status of the `highWaterMark`.",
                    "type": "number"
                },
                "writableNeedDrain": {
                    "description": "Is `true` if the stream's buffer has been full and stream will emit 'drain'.",
                    "type": "boolean"
                },
                "writableObjectMode": {
                    "description": "Getter for the property `objectMode` of a given `Writable` stream.",
                    "type": "boolean"
                }
            },
            "required": [
                "closed",
                "destroyed",
                "errored",
                "writable",
                "writableCorked",
                "writableEnded",
                "writableFinished",
                "writableHighWaterMark",
                "writableLength",
                "writableNeedDrain",
                "writableObjectMode"
            ],
            "type": "object"
        },
        "import(\"events\")": {
            "additionalProperties": false,
            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:",
            "type": "object"
        },
        "typeofDuplex": {
            "additionalProperties": false,
            "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`",
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/Duplex"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofPassThrough": {
            "additionalProperties": false,
            "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams.",
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/PassThrough"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofReadable": {
            "additionalProperties": false,
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/Readable"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofStream": {
            "additionalProperties": false,
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/Stream"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofTransform": {
            "additionalProperties": false,
            "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`",
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/Transform"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofWritable": {
            "additionalProperties": false,
            "properties": {
                "Duplex": {
                    "$ref": "#/definitions/typeofDuplex",
                    "description": "Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n\nExamples of `Duplex` streams include:\n\n* `TCP sockets`\n* `zlib streams`\n* `crypto streams`"
                },
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")",
                    "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:"
                },
                "PassThrough": {
                    "$ref": "#/definitions/typeofPassThrough",
                    "description": "The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\nprimarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams."
                },
                "Readable": {
                    "$ref": "#/definitions/typeofReadable"
                },
                "Stream": {
                    "$ref": "#/definitions/typeofStream"
                },
                "Transform": {
                    "$ref": "#/definitions/typeofTransform",
                    "description": "Transform streams are `Duplex` streams where the output is in some way\nrelated to the input. Like all `Duplex` streams, `Transform` streams\nimplement both the `Readable` and `Writable` interfaces.\n\nExamples of `Transform` streams include:\n\n* `zlib streams`\n* `crypto streams`"
                },
                "Writable": {
                    "$ref": "#/definitions/typeofWritable"
                },
                "addAbortSignal": {
                    "additionalProperties": false,
                    "description": "Attaches an AbortSignal to a readable or writeable stream. This lets code\ncontrol stream destruction using an `AbortController`.\n\nCalling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.\n\n```js\nconst fs = require('fs');\n\nconst controller = new AbortController();\nconst read = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n// Later, abort the operation closing the stream\ncontroller.abort();\n```\n\nOr using an `AbortSignal` with a readable stream as an async iterable:\n\n```js\nconst controller = new AbortController();\nsetTimeout(() => controller.abort(), 10_000); // set a timeout\nconst stream = addAbortSignal(\n  controller.signal,\n  fs.createReadStream(('object.json'))\n);\n(async () => {\n  try {\n    for await (const chunk of stream) {\n      await process(chunk);\n    }\n  } catch (e) {\n    if (e.name === 'AbortError') {\n      // The operation was cancelled\n    } else {\n      throw e;\n    }\n  }\n})();\n```",
                    "type": "object"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "consumers": {
                    "additionalProperties": false,
                    "properties": {
                        "arrayBuffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "blob": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "buffer": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "json": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "text": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "arrayBuffer",
                        "blob",
                        "buffer",
                        "json",
                        "text"
                    ],
                    "type": "object"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "finished": {
                    "additionalProperties": false,
                    "description": "A function to get notified when a stream is no longer readable, writable\nor has experienced an error or a premature close event.\n\n```js\nconst { finished } = require('stream');\n\nconst rs = fs.createReadStream('archive.tar');\n\nfinished(rs, (err) => {\n  if (err) {\n    console.error('Stream failed.', err);\n  } else {\n    console.log('Stream is done reading.');\n  }\n});\n\nrs.resume(); // Drain the stream.\n```\n\nEspecially useful in error handling scenarios where a stream is destroyed\nprematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.\n\nThe `finished` API provides promise version:\n\n```js\nconst { finished } = require('stream/promises');\n\nconst rs = fs.createReadStream('archive.tar');\n\nasync function run() {\n  await finished(rs);\n  console.log('Stream is done reading.');\n}\n\nrun().catch(console.error);\nrs.resume(); // Drain the stream.\n```\n\n`stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\ninvoked. The reason for this is so that unexpected `'error'` events (due to\nincorrect stream implementations) do not cause unexpected crashes.\nIf this is unwanted behavior then the returned cleanup function needs to be\ninvoked in the callback:\n\n```js\nconst cleanup = finished(rs, (err) => {\n  cleanup();\n  // ...\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "isErrored": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream has encountered an error.",
                    "type": "object"
                },
                "isReadable": {
                    "additionalProperties": false,
                    "description": "Returns whether the stream is readable.",
                    "type": "object"
                },
                "pipeline": {
                    "additionalProperties": false,
                    "description": "A module method to pipe between streams and generators forwarding errors and\nproperly cleaning up and provide a callback when the pipeline is complete.\n\n```js\nconst { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Use the pipeline API to easily pipe a series of streams\n// together and get notified when the pipeline is fully done.\n\n// A pipeline to gzip a potentially huge tar file efficiently:\n\npipeline(\n  fs.createReadStream('archive.tar'),\n  zlib.createGzip(),\n  fs.createWriteStream('archive.tar.gz'),\n  (err) => {\n    if (err) {\n      console.error('Pipeline failed.', err);\n    } else {\n      console.log('Pipeline succeeded.');\n    }\n  }\n);\n```\n\nThe `pipeline` API provides a promise version, which can also\nreceive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with\nan`AbortError`.\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nTo use an `AbortSignal`, pass it inside an options object,\nas the last argument:\n\n```js\nconst { pipeline } = require('stream/promises');\n\nasync function run() {\n  const ac = new AbortController();\n  const signal = ac.signal;\n\n  setTimeout(() => ac.abort(), 1);\n  await pipeline(\n    fs.createReadStream('archive.tar'),\n    zlib.createGzip(),\n    fs.createWriteStream('archive.tar.gz'),\n    { signal },\n  );\n}\n\nrun().catch(console.error); // AbortError\n```\n\nThe `pipeline` API also supports async generators:\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    fs.createReadStream('lowercase.txt'),\n    async function* (source, { signal }) {\n      source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.\n      for await (const chunk of source) {\n        yield await processChunk(chunk, { signal });\n      }\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\nRemember to handle the `signal` argument passed into the async generator.\nEspecially in the case where the async generator is the source for the\npipeline (i.e. first argument) or the pipeline will never complete.\n\n```js\nconst { pipeline } = require('stream/promises');\nconst fs = require('fs');\n\nasync function run() {\n  await pipeline(\n    async function* ({ signal }) {\n      await someLongRunningfn({ signal });\n      yield 'asd';\n    },\n    fs.createWriteStream('uppercase.txt')\n  );\n  console.log('Pipeline succeeded.');\n}\n\nrun().catch(console.error);\n```\n\n`stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n\n* `Readable` streams which have emitted `'end'` or `'close'`.\n* `Writable` streams which have emitted `'finish'` or `'close'`.\n\n`stream.pipeline()` leaves dangling event listeners on the streams\nafter the `callback` has been invoked. In the case of reuse of streams after\nfailure, this can cause event listener leaks and swallowed errors. If the last\nstream is readable, dangling event listeners will be removed so that the last\nstream can be consumed later.\n\n`stream.pipeline()` closes all the streams when an error is raised.\nThe `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\nonce it would destroy the socket without sending the expected response.\nSee the example below:\n\n```js\nconst fs = require('fs');\nconst http = require('http');\nconst { pipeline } = require('stream');\n\nconst server = http.createServer((req, res) => {\n  const fileStream = fs.createReadStream('./fileNotExist.txt');\n  pipeline(fileStream, res, (err) => {\n    if (err) {\n      console.log(err); // No such file\n      // this message can't be sent once `pipeline` already destroyed the socket\n      return res.end('error!!!');\n    }\n  });\n});\n```",
                    "properties": {
                        "__promisify__": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "__promisify__"
                    ],
                    "type": "object"
                },
                "promises": {
                    "additionalProperties": false,
                    "properties": {
                        "finished": {
                            "additionalProperties": false,
                            "type": "object"
                        },
                        "pipeline": {
                            "additionalProperties": false,
                            "type": "object"
                        }
                    },
                    "required": [
                        "finished",
                        "pipeline"
                    ],
                    "type": "object"
                },
                "prototype": {
                    "$ref": "#/definitions/Writable"
                }
            },
            "required": [
                "Duplex",
                "EventEmitter",
                "PassThrough",
                "Readable",
                "Stream",
                "Transform",
                "Writable",
                "addAbortSignal",
                "captureRejectionSymbol",
                "captureRejections",
                "consumers",
                "defaultMaxListeners",
                "errorMonitor",
                "finished",
                "isErrored",
                "isReadable",
                "pipeline",
                "promises",
                "prototype"
            ],
            "type": "object"
        },
        "typeofcaptureRejectionSymbol": {
            "additionalProperties": false,
            "properties": {
                "__@toStringTag@533": {
                    "type": "string"
                },
                "description": {
                    "type": "string"
                }
            },
            "required": [
                "__@toStringTag@533"
            ],
            "type": "object"
        },
        "typeoferrorMonitor": {
            "additionalProperties": false,
            "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed.",
            "properties": {
                "__@toStringTag@533": {
                    "type": "string"
                },
                "description": {
                    "type": "string"
                }
            },
            "required": [
                "__@toStringTag@533"
            ],
            "type": "object"
        },
        "typeofimport(\"events\")": {
            "additionalProperties": false,
            "description": "The `EventEmitter` class is defined and exposed by the `events` module:\n\n```js\nconst EventEmitter = require('events');\n```\n\nAll `EventEmitter`s emit the event `'newListener'` when new listeners are\nadded and `'removeListener'` when existing listeners are removed.\n\nIt supports the following option:",
            "properties": {
                "EventEmitter": {
                    "$ref": "#/definitions/typeofimport(\"events\")"
                },
                "captureRejectionSymbol": {
                    "$ref": "#/definitions/typeofcaptureRejectionSymbol"
                },
                "captureRejections": {
                    "description": "Sets or gets the default captureRejection value for all emitters.",
                    "type": "boolean"
                },
                "defaultMaxListeners": {
                    "type": "number"
                },
                "errorMonitor": {
                    "$ref": "#/definitions/typeoferrorMonitor",
                    "description": "This symbol shall be used to install a listener for only monitoring `'error'`\nevents. Listeners installed using this symbol are called before the regular\n`'error'` listeners are called.\n\nInstalling a listener using this symbol does not change the behavior once an\n`'error'` event is emitted, therefore the process will still crash if no\nregular `'error'` listener is installed."
                },
                "prototype": {
                    "$ref": "#/definitions/import(\"events\")"
                }
            },
            "required": [
                "EventEmitter",
                "captureRejectionSymbol",
                "captureRejections",
                "defaultMaxListeners",
                "errorMonitor",
                "prototype"
            ],
            "type": "object"
        }
    },
    "properties": {
        "appPaths": {
            "items": {
                "type": "string"
            },
            "type": "array"
        },
        "basePath": {
            "type": "string"
        },
        "http": {
            "$ref": "#/definitions/ServerOptions<typeofIncomingMessage,typeofServerResponse>"
        },
        "http2": {
            "$ref": "#/definitions/ServerOptions"
        },
        "https": {
            "$ref": "#/definitions/ServerOptions<typeofIncomingMessage,typeofServerResponse>_1"
        },
        "langs": {
            "items": {
                "type": "string"
            },
            "type": "array"
        },
        "listenOptions": {
            "$ref": "#/definitions/ListenOptions"
        },
        "protocol": {
            "default": "http",
            "enum": [
                "http",
                "http2",
                "https"
            ],
            "type": "string"
        }
    },
    "required": [
        "protocol"
    ],
    "type": "object"
}

